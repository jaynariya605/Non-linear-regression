{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNYIbp2rMxRpJ5t2l/eS7vk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaynariya605/Non-linear-regression/blob/master/assign2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWx1acs93I7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the pandas library to read our dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import the numpy library to work with and manipulate the data\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBS7bd4k3RSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data from google drive\n",
        "#data = pd.read_csv('train.tsv', sep='\\t')\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNGItdC3SDT",
        "colab_type": "code",
        "outputId": "569bb74d-e85e-4f1c-eadb-fb6fa8531258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Check the head of the dataframe\n",
        "data.head(20)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>the adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>the</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>adage</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>that</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>what</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PhraseId  ...  Sentiment\n",
              "0          1  ...          1\n",
              "1          2  ...          2\n",
              "2          3  ...          2\n",
              "3          4  ...          2\n",
              "4          5  ...          2\n",
              "5          6  ...          2\n",
              "6          7  ...          2\n",
              "7          8  ...          2\n",
              "8          9  ...          2\n",
              "9         10  ...          2\n",
              "10        11  ...          2\n",
              "11        12  ...          2\n",
              "12        13  ...          2\n",
              "13        14  ...          2\n",
              "14        15  ...          2\n",
              "15        16  ...          2\n",
              "16        17  ...          2\n",
              "17        18  ...          2\n",
              "18        19  ...          2\n",
              "19        20  ...          2\n",
              "\n",
              "[20 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVgNhAAA3UPX",
        "colab_type": "code",
        "outputId": "7e671827-7b14-4028-8a32-1d75945a5b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check the shape of df\n",
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T6JaLMb3WqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of unique sentences\n",
        "numSentences = data['SentenceId'].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyoOiIWg3-DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract full sentences only from the dataset\n",
        "fullSentences = []\n",
        "curSentence = 0\n",
        "for i in range(data.shape[0]):\n",
        "  if data['SentenceId'][i]> curSentence:\n",
        "    fullSentences.append((data['Phrase'][i], data['Sentiment'][i]))\n",
        "    curSentence = curSentence +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iyaczKF4Am6",
        "colab_type": "code",
        "outputId": "07f5d153-c5dc-4ecc-f4b2-1b2b9514493c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(fullSentences)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uew6gz44C1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put data into a df\n",
        "all_data = pd.DataFrame(fullSentences,\n",
        "                                columns=['Phrase', 'Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_86BdkRu4wDi",
        "colab_type": "code",
        "outputId": "438afbe5-8ffa-431f-befc-0e8a53362187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "all_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This quiet , introspective and entertaining in...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A positively thrilling combination of ethnogra...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aggressive self-glorification and a manipulati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8539</th>\n",
              "      <td>... either you 're willing to go with this cla...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8540</th>\n",
              "      <td>Despite these annoyances , the capable Claybur...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8541</th>\n",
              "      <td>-LRB- Tries -RRB- to parody a genre that 's al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8542</th>\n",
              "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8543</th>\n",
              "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8544 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Phrase  Sentiment\n",
              "0     A series of escapades demonstrating the adage ...          1\n",
              "1     This quiet , introspective and entertaining in...          4\n",
              "2     Even fans of Ismail Merchant 's work , I suspe...          1\n",
              "3     A positively thrilling combination of ethnogra...          3\n",
              "4     Aggressive self-glorification and a manipulati...          1\n",
              "...                                                 ...        ...\n",
              "8539  ... either you 're willing to go with this cla...          2\n",
              "8540  Despite these annoyances , the capable Claybur...          2\n",
              "8541  -LRB- Tries -RRB- to parody a genre that 's al...          1\n",
              "8542  The movie 's downfall is to substitute plot fo...          1\n",
              "8543  The film is darkly atmospheric , with Herrmann...          2\n",
              "\n",
              "[8544 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZC1rZfw4bBN",
        "colab_type": "code",
        "outputId": "efdc24c9-4e0a-487d-8fd6-093f856fca8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl31S7xY4ciF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "#convert data into format for the previous labs\n",
        "\n",
        "#use full dataset\n",
        "#for i in range(data.shape[0]):\n",
        "#  tmpWords = word_tokenize(data['Phrase'][i])\n",
        "#  documents.append((tmpWords, data['Sentiment'][i]))\n",
        "\n",
        "# Use only complete sentences\n",
        "for i in range(all_data.shape[0]):\n",
        "  tmpWords = word_tokenize(all_data['Phrase'][i])\n",
        "  documents.append((tmpWords, all_data['Sentiment'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jwQUAy3-_rx",
        "colab_type": "code",
        "outputId": "f5e4e9e4-57c2-4071-a5e3-84116622568c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = False\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n",
        "\n",
        "for l in range(len(documents)):\n",
        "  label = documents[l][1]\n",
        "  tmpReview = []\n",
        "  for w in documents[l][0]:\n",
        "    newWord = w\n",
        "    if remove_stopwords and (w in stopwords_en):\n",
        "      continue\n",
        "    if removePuncs and (w in punctuations):\n",
        "      continue\n",
        "    if useStemming:\n",
        "      #newWord = porter.stem(newWord)\n",
        "      newWord = lancaster.stem(newWord)\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord)\n",
        "  documents[l] = (' '.join(tmpReview), label)\n",
        "print(documents[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('This quiet introspective and entertaining independent is worth seeking', 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK9o4mjGFQ-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.DataFrame(documents,\n",
        "                                columns=['text', 'sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK2abyPu5v43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = all_data['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aippKoPAYbnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "7c252952-2409-4ae7-e898-88b75c7e9f6f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from keras.utils import to_categorical\n",
        "# Transform each text into a vector of word counts\n",
        "vec = CountVectorizer(stop_words=\"english\",\n",
        "                             ngram_range=(1, 1))\n",
        "X = vec.fit_transform(X).A\n",
        "Y = to_categorical(all_data['sentiment'].values)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMMXBiOmYSsq",
        "colab": {}
      },
      "source": [
        "\n",
        "# Splits the dataset so 70% is used for training and 30% for testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3,random_state = 2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOTEcNxMy65w",
        "colab_type": "code",
        "outputId": "47027e69-4ba1-4f0b-d1c4-c786691f153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5980, 14879)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3KmpR2sz16A",
        "colab_type": "code",
        "outputId": "98ede809-b318-406a-8e00-732f6434539e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2564, 14879)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlTKTmiYCVrq",
        "colab_type": "code",
        "outputId": "1fb543b5-49eb-4286-ee76-9de3bcfe24d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2564, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt_K6ieD4PAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33u6RbkTwTVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D , AveragePooling1D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptsh740ODNJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3FMVwSxBZXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nrows, ncols = x_train.shape\n",
        "x_train1 = x_train.reshape(nrows, ncols,1)\n",
        "\n",
        "nrows, ncols = x_test.shape\n",
        "x_test1 = x_test.reshape(nrows, ncols,1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgnxRHWBuDW",
        "colab_type": "code",
        "outputId": "07506e2f-0f66-4d1e-b5ae-6d4c3554a637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train1.shape[1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14879"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-6NTq4vzTJW",
        "colab_type": "code",
        "outputId": "c591fab6-5218-43ce-b7da-999034679211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv1D(32, kernel_size=2,input_shape=(x_train1.shape[1],1),padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Conv1D(64, kernel_size=2, padding='same', activation='relu'))\n",
        "model2.add(AveragePooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "# Output layer\n",
        "model2.add(Dense(5, activation='softmax'))\n",
        "model2.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 14879, 32)         96        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 7439, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 7439, 64)          4160      \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 3719, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 238016)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1190085   \n",
            "=================================================================\n",
            "Total params: 1,194,341\n",
            "Trainable params: 1,194,341\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_1w_2l7AKzY",
        "colab_type": "code",
        "outputId": "854bce1d-27f2-4e22-fa9f-068f41e4588e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "history = model2.fit(x_train1, y_train, validation_data=(x_test1, y_test), epochs=30, batch_size=32, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 5980 samples, validate on 2564 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "5980/5980 [==============================] - 21s 4ms/step - loss: 1.5117 - acc: 0.3431 - f1_m: 0.0556 - precision_m: 0.3523 - recall_m: 0.0316 - val_loss: 1.4196 - val_acc: 0.3849 - val_f1_m: 0.1226 - val_precision_m: 0.5212 - val_recall_m: 0.0710\n",
            "Epoch 2/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.9692 - acc: 0.6164 - f1_m: 0.5545 - precision_m: 0.7249 - recall_m: 0.4555 - val_loss: 1.5920 - val_acc: 0.3729 - val_f1_m: 0.2729 - val_precision_m: 0.4090 - val_recall_m: 0.2067\n",
            "Epoch 3/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.5188 - acc: 0.8038 - f1_m: 0.7950 - precision_m: 0.8525 - recall_m: 0.7465 - val_loss: 2.2990 - val_acc: 0.3584 - val_f1_m: 0.3363 - val_precision_m: 0.3775 - val_recall_m: 0.3042\n",
            "Epoch 4/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.2694 - acc: 0.9060 - f1_m: 0.9073 - precision_m: 0.9292 - recall_m: 0.8871 - val_loss: 3.2575 - val_acc: 0.3452 - val_f1_m: 0.3349 - val_precision_m: 0.3534 - val_recall_m: 0.3186\n",
            "Epoch 5/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.1390 - acc: 0.9522 - f1_m: 0.9527 - precision_m: 0.9632 - recall_m: 0.9428 - val_loss: 4.3208 - val_acc: 0.3397 - val_f1_m: 0.3330 - val_precision_m: 0.3428 - val_recall_m: 0.3241\n",
            "Epoch 6/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0817 - acc: 0.9729 - f1_m: 0.9738 - precision_m: 0.9792 - recall_m: 0.9686 - val_loss: 5.0666 - val_acc: 0.3319 - val_f1_m: 0.3275 - val_precision_m: 0.3341 - val_recall_m: 0.3214\n",
            "Epoch 7/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0535 - acc: 0.9853 - f1_m: 0.9852 - precision_m: 0.9896 - recall_m: 0.9809 - val_loss: 5.6125 - val_acc: 0.3350 - val_f1_m: 0.3327 - val_precision_m: 0.3377 - val_recall_m: 0.3280\n",
            "Epoch 8/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0369 - acc: 0.9885 - f1_m: 0.9891 - precision_m: 0.9928 - recall_m: 0.9856 - val_loss: 6.0409 - val_acc: 0.3300 - val_f1_m: 0.3264 - val_precision_m: 0.3310 - val_recall_m: 0.3222\n",
            "Epoch 9/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0318 - acc: 0.9900 - f1_m: 0.9905 - precision_m: 0.9934 - recall_m: 0.9876 - val_loss: 6.1896 - val_acc: 0.3323 - val_f1_m: 0.3311 - val_precision_m: 0.3352 - val_recall_m: 0.3272\n",
            "Epoch 10/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0246 - acc: 0.9923 - f1_m: 0.9929 - precision_m: 0.9956 - recall_m: 0.9903 - val_loss: 6.5296 - val_acc: 0.3366 - val_f1_m: 0.3337 - val_precision_m: 0.3373 - val_recall_m: 0.3303\n",
            "Epoch 11/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0220 - acc: 0.9926 - f1_m: 0.9932 - precision_m: 0.9955 - recall_m: 0.9910 - val_loss: 6.6530 - val_acc: 0.3331 - val_f1_m: 0.3304 - val_precision_m: 0.3333 - val_recall_m: 0.3276\n",
            "Epoch 12/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0189 - acc: 0.9946 - f1_m: 0.9952 - precision_m: 0.9975 - recall_m: 0.9930 - val_loss: 6.8549 - val_acc: 0.3346 - val_f1_m: 0.3331 - val_precision_m: 0.3356 - val_recall_m: 0.3307\n",
            "Epoch 13/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0177 - acc: 0.9943 - f1_m: 0.9949 - precision_m: 0.9970 - recall_m: 0.9928 - val_loss: 6.9838 - val_acc: 0.3339 - val_f1_m: 0.3323 - val_precision_m: 0.3349 - val_recall_m: 0.3300\n",
            "Epoch 14/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0184 - acc: 0.9945 - f1_m: 0.9948 - precision_m: 0.9971 - recall_m: 0.9925 - val_loss: 6.9919 - val_acc: 0.3264 - val_f1_m: 0.3251 - val_precision_m: 0.3269 - val_recall_m: 0.3233\n",
            "Epoch 15/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0171 - acc: 0.9946 - f1_m: 0.9950 - precision_m: 0.9971 - recall_m: 0.9930 - val_loss: 7.0994 - val_acc: 0.3241 - val_f1_m: 0.3233 - val_precision_m: 0.3257 - val_recall_m: 0.3210\n",
            "Epoch 16/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0160 - acc: 0.9945 - f1_m: 0.9949 - precision_m: 0.9973 - recall_m: 0.9926 - val_loss: 7.2450 - val_acc: 0.3296 - val_f1_m: 0.3274 - val_precision_m: 0.3297 - val_recall_m: 0.3253\n",
            "Epoch 17/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0160 - acc: 0.9946 - f1_m: 0.9950 - precision_m: 0.9970 - recall_m: 0.9931 - val_loss: 7.3171 - val_acc: 0.3300 - val_f1_m: 0.3272 - val_precision_m: 0.3292 - val_recall_m: 0.3253\n",
            "Epoch 18/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0158 - acc: 0.9952 - f1_m: 0.9955 - precision_m: 0.9976 - recall_m: 0.9935 - val_loss: 7.3662 - val_acc: 0.3284 - val_f1_m: 0.3254 - val_precision_m: 0.3275 - val_recall_m: 0.3233\n",
            "Epoch 19/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0149 - acc: 0.9950 - f1_m: 0.9954 - precision_m: 0.9973 - recall_m: 0.9935 - val_loss: 7.4259 - val_acc: 0.3346 - val_f1_m: 0.3341 - val_precision_m: 0.3361 - val_recall_m: 0.3323\n",
            "Epoch 20/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0198 - acc: 0.9938 - f1_m: 0.9943 - precision_m: 0.9965 - recall_m: 0.9921 - val_loss: 7.2186 - val_acc: 0.3288 - val_f1_m: 0.3257 - val_precision_m: 0.3283 - val_recall_m: 0.3233\n",
            "Epoch 21/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0632 - acc: 0.9788 - f1_m: 0.9788 - precision_m: 0.9818 - recall_m: 0.9759 - val_loss: 6.0049 - val_acc: 0.3241 - val_f1_m: 0.3225 - val_precision_m: 0.3274 - val_recall_m: 0.3179\n",
            "Epoch 22/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.1598 - acc: 0.9438 - f1_m: 0.9443 - precision_m: 0.9512 - recall_m: 0.9376 - val_loss: 5.2262 - val_acc: 0.3284 - val_f1_m: 0.3246 - val_precision_m: 0.3319 - val_recall_m: 0.3179\n",
            "Epoch 23/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0850 - acc: 0.9706 - f1_m: 0.9713 - precision_m: 0.9765 - recall_m: 0.9662 - val_loss: 5.8652 - val_acc: 0.3245 - val_f1_m: 0.3212 - val_precision_m: 0.3269 - val_recall_m: 0.3159\n",
            "Epoch 24/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0318 - acc: 0.9905 - f1_m: 0.9911 - precision_m: 0.9943 - recall_m: 0.9880 - val_loss: 6.4460 - val_acc: 0.3210 - val_f1_m: 0.3178 - val_precision_m: 0.3215 - val_recall_m: 0.3144\n",
            "Epoch 25/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0154 - acc: 0.9952 - f1_m: 0.9954 - precision_m: 0.9980 - recall_m: 0.9930 - val_loss: 6.8635 - val_acc: 0.3186 - val_f1_m: 0.3163 - val_precision_m: 0.3191 - val_recall_m: 0.3136\n",
            "Epoch 26/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0155 - acc: 0.9946 - f1_m: 0.9949 - precision_m: 0.9973 - recall_m: 0.9925 - val_loss: 6.9824 - val_acc: 0.3206 - val_f1_m: 0.3154 - val_precision_m: 0.3185 - val_recall_m: 0.3124\n",
            "Epoch 27/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0134 - acc: 0.9952 - f1_m: 0.9955 - precision_m: 0.9977 - recall_m: 0.9935 - val_loss: 7.1431 - val_acc: 0.3179 - val_f1_m: 0.3159 - val_precision_m: 0.3187 - val_recall_m: 0.3132\n",
            "Epoch 28/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0131 - acc: 0.9957 - f1_m: 0.9958 - precision_m: 0.9980 - recall_m: 0.9936 - val_loss: 7.2121 - val_acc: 0.3179 - val_f1_m: 0.3155 - val_precision_m: 0.3179 - val_recall_m: 0.3132\n",
            "Epoch 29/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0131 - acc: 0.9955 - f1_m: 0.9958 - precision_m: 0.9982 - recall_m: 0.9935 - val_loss: 7.2458 - val_acc: 0.3171 - val_f1_m: 0.3144 - val_precision_m: 0.3168 - val_recall_m: 0.3120\n",
            "Epoch 30/30\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0126 - acc: 0.9958 - f1_m: 0.9960 - precision_m: 0.9981 - recall_m: 0.9940 - val_loss: 7.2756 - val_acc: 0.3194 - val_f1_m: 0.3163 - val_precision_m: 0.3187 - val_recall_m: 0.3140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wTEJgQJRDkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('model2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luX87UOrKmRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Conv1D(32, kernel_size=3,input_shape=(x_train1.shape[1],1), padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model3.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model3.add(Flatten())\n",
        "\n",
        "# Output layer\n",
        "model3.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSMgPNqJRUFo",
        "colab_type": "code",
        "outputId": "d2b1c462-6368-4ee7-8049-785cbb51d67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "history = model3.fit(x_train1, y_train, validation_data=(x_test1, y_test), epochs=10, batch_size=30, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5980 samples, validate on 2564 samples\n",
            "Epoch 1/10\n",
            "5980/5980 [==============================] - 10s 2ms/step - loss: 1.5030 - acc: 0.3410 - f1_m: 0.0475 - precision_m: 0.3054 - recall_m: 0.0266 - val_loss: 1.4279 - val_acc: 0.3814 - val_f1_m: 0.0859 - val_precision_m: 0.4431 - val_recall_m: 0.0484\n",
            "Epoch 2/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.9292 - acc: 0.6306 - f1_m: 0.5768 - precision_m: 0.7389 - recall_m: 0.4823 - val_loss: 1.6178 - val_acc: 0.3662 - val_f1_m: 0.2834 - val_precision_m: 0.4111 - val_recall_m: 0.2180\n",
            "Epoch 3/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.4814 - acc: 0.8221 - f1_m: 0.8153 - precision_m: 0.8722 - recall_m: 0.7676 - val_loss: 2.3963 - val_acc: 0.3506 - val_f1_m: 0.3272 - val_precision_m: 0.3659 - val_recall_m: 0.2968\n",
            "Epoch 4/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.2490 - acc: 0.9159 - f1_m: 0.9138 - precision_m: 0.9369 - recall_m: 0.8926 - val_loss: 3.3974 - val_acc: 0.3417 - val_f1_m: 0.3307 - val_precision_m: 0.3467 - val_recall_m: 0.3167\n",
            "Epoch 5/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.1384 - acc: 0.9552 - f1_m: 0.9554 - precision_m: 0.9666 - recall_m: 0.9448 - val_loss: 4.1806 - val_acc: 0.3514 - val_f1_m: 0.3448 - val_precision_m: 0.3551 - val_recall_m: 0.3354\n",
            "Epoch 6/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0799 - acc: 0.9761 - f1_m: 0.9764 - precision_m: 0.9821 - recall_m: 0.9709 - val_loss: 4.8937 - val_acc: 0.3448 - val_f1_m: 0.3400 - val_precision_m: 0.3471 - val_recall_m: 0.3335\n",
            "Epoch 7/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0496 - acc: 0.9856 - f1_m: 0.9859 - precision_m: 0.9911 - recall_m: 0.9809 - val_loss: 5.4767 - val_acc: 0.3463 - val_f1_m: 0.3425 - val_precision_m: 0.3489 - val_recall_m: 0.3366\n",
            "Epoch 8/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0333 - acc: 0.9900 - f1_m: 0.9900 - precision_m: 0.9933 - recall_m: 0.9868 - val_loss: 5.8596 - val_acc: 0.3358 - val_f1_m: 0.3338 - val_precision_m: 0.3387 - val_recall_m: 0.3292\n",
            "Epoch 9/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0297 - acc: 0.9906 - f1_m: 0.9911 - precision_m: 0.9940 - recall_m: 0.9883 - val_loss: 6.0469 - val_acc: 0.3420 - val_f1_m: 0.3384 - val_precision_m: 0.3431 - val_recall_m: 0.3339\n",
            "Epoch 10/10\n",
            "5980/5980 [==============================] - 9s 2ms/step - loss: 0.0253 - acc: 0.9925 - f1_m: 0.9925 - precision_m: 0.9951 - recall_m: 0.9900 - val_loss: 6.2431 - val_acc: 0.3300 - val_f1_m: 0.3295 - val_precision_m: 0.3330 - val_recall_m: 0.3261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p1FRHkHse2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.save_weights('model3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6oHCsvbyx8j",
        "colab_type": "code",
        "outputId": "9a769c39-e446-42f3-ac1b-dbe11cfe3aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras import optimizers\n",
        "lr = 1e-3\n",
        "Nadam=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=x_train.shape[1]))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='Nadam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 32)                476160    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 45        \n",
            "=================================================================\n",
            "Total params: 476,869\n",
            "Trainable params: 476,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHvPOmBCz1Kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "3afda7b2-3cb9-499d-a0ab-e3103a2d3e68"
      },
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=15, batch_size=10000, verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5980 samples, validate on 2564 samples\n",
            "Epoch 1/15\n",
            "5980/5980 [==============================] - 1s 193us/step - loss: 1.6068 - acc: 0.2610 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.6032 - val_acc: 0.2886 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/15\n",
            "5980/5980 [==============================] - 1s 100us/step - loss: 1.5948 - acc: 0.3764 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5992 - val_acc: 0.3085 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 3/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.5831 - acc: 0.4258 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5947 - val_acc: 0.3233 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.5699 - acc: 0.4552 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5894 - val_acc: 0.3335 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 5/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.5550 - acc: 0.4734 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5835 - val_acc: 0.3444 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 6/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.5378 - acc: 0.4848 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5769 - val_acc: 0.3502 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 7/15\n",
            "5980/5980 [==============================] - 1s 86us/step - loss: 1.5187 - acc: 0.4901 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5697 - val_acc: 0.3573 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 8/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.4975 - acc: 0.4958 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5627 - val_acc: 0.3651 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/15\n",
            "5980/5980 [==============================] - 1s 84us/step - loss: 1.4741 - acc: 0.5022 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5552 - val_acc: 0.3608 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 10/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.4495 - acc: 0.5048 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5482 - val_acc: 0.3678 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 11/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.4230 - acc: 0.5102 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.5410 - val_acc: 0.3651 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 12/15\n",
            "5980/5980 [==============================] - 1s 86us/step - loss: 1.3956 - acc: 0.5117 - f1_m: 0.0013 - precision_m: 1.0000 - recall_m: 6.6890e-04 - val_loss: 1.5346 - val_acc: 0.3666 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 13/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.3672 - acc: 0.5207 - f1_m: 0.0050 - precision_m: 1.0000 - recall_m: 0.0025 - val_loss: 1.5284 - val_acc: 0.3658 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 14/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.3382 - acc: 0.5214 - f1_m: 0.0146 - precision_m: 1.0000 - recall_m: 0.0074 - val_loss: 1.5228 - val_acc: 0.3643 - val_f1_m: 7.7942e-04 - val_precision_m: 0.5000 - val_recall_m: 3.9002e-04\n",
            "Epoch 15/15\n",
            "5980/5980 [==============================] - 1s 85us/step - loss: 1.3084 - acc: 0.5313 - f1_m: 0.0361 - precision_m: 0.9821 - recall_m: 0.0184 - val_loss: 1.5182 - val_acc: 0.3647 - val_f1_m: 0.0016 - val_precision_m: 0.4000 - val_recall_m: 7.8003e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPE3_QtXLocf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b7af2e39-b285-483d-f26b-ee387f35384d"
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size=10000, verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r2564/2564 [==============================] - 0s 59us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5182139873504639,\n",
              " 0.36466458439826965,\n",
              " 0.0015570255927741528,\n",
              " 0.4000000059604645,\n",
              " 0.0007800312014296651]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}